{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9319664492078286,
  "eval_steps": 500,
  "global_step": 4000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.06442886590957642,
      "learning_rate": 4.988350419384902e-05,
      "loss": 2.6273,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.09226460009813309,
      "learning_rate": 4.976700838769805e-05,
      "loss": 2.6649,
      "step": 20
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1305578649044037,
      "learning_rate": 4.9650512581547066e-05,
      "loss": 2.6156,
      "step": 30
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1607576161623001,
      "learning_rate": 4.9534016775396085e-05,
      "loss": 2.6118,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.18533040583133698,
      "learning_rate": 4.9417520969245104e-05,
      "loss": 2.6079,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2121846228837967,
      "learning_rate": 4.930102516309413e-05,
      "loss": 2.593,
      "step": 60
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.22856444120407104,
      "learning_rate": 4.9184529356943156e-05,
      "loss": 2.5988,
      "step": 70
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.26435017585754395,
      "learning_rate": 4.9068033550792175e-05,
      "loss": 2.6102,
      "step": 80
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2588188350200653,
      "learning_rate": 4.8951537744641194e-05,
      "loss": 2.5889,
      "step": 90
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2513395845890045,
      "learning_rate": 4.883504193849022e-05,
      "loss": 2.5329,
      "step": 100
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.28140273690223694,
      "learning_rate": 4.871854613233924e-05,
      "loss": 2.5584,
      "step": 110
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2676359713077545,
      "learning_rate": 4.860205032618826e-05,
      "loss": 2.5185,
      "step": 120
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2633787989616394,
      "learning_rate": 4.848555452003728e-05,
      "loss": 2.4961,
      "step": 130
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.25995442271232605,
      "learning_rate": 4.83690587138863e-05,
      "loss": 2.5082,
      "step": 140
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.23588049411773682,
      "learning_rate": 4.825256290773532e-05,
      "loss": 2.5122,
      "step": 150
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.2552969753742218,
      "learning_rate": 4.813606710158435e-05,
      "loss": 2.4866,
      "step": 160
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.22356374561786652,
      "learning_rate": 4.8019571295433367e-05,
      "loss": 2.4584,
      "step": 170
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.24753034114837646,
      "learning_rate": 4.790307548928239e-05,
      "loss": 2.4687,
      "step": 180
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.2585037350654602,
      "learning_rate": 4.778657968313141e-05,
      "loss": 2.4515,
      "step": 190
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.23182615637779236,
      "learning_rate": 4.767008387698043e-05,
      "loss": 2.4208,
      "step": 200
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.24738797545433044,
      "learning_rate": 4.755358807082945e-05,
      "loss": 2.4372,
      "step": 210
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.24035201966762543,
      "learning_rate": 4.7437092264678475e-05,
      "loss": 2.4274,
      "step": 220
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.22705307602882385,
      "learning_rate": 4.7320596458527494e-05,
      "loss": 2.4231,
      "step": 230
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.2439308613538742,
      "learning_rate": 4.720410065237651e-05,
      "loss": 2.4266,
      "step": 240
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.24851055443286896,
      "learning_rate": 4.708760484622554e-05,
      "loss": 2.4273,
      "step": 250
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.23553387820720673,
      "learning_rate": 4.697110904007456e-05,
      "loss": 2.4115,
      "step": 260
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.2718559503555298,
      "learning_rate": 4.6854613233923584e-05,
      "loss": 2.4215,
      "step": 270
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.2420804798603058,
      "learning_rate": 4.67381174277726e-05,
      "loss": 2.4254,
      "step": 280
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.2717609405517578,
      "learning_rate": 4.662162162162162e-05,
      "loss": 2.3869,
      "step": 290
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.2856113016605377,
      "learning_rate": 4.650512581547065e-05,
      "loss": 2.4055,
      "step": 300
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.24477854371070862,
      "learning_rate": 4.638863000931967e-05,
      "loss": 2.383,
      "step": 310
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.2642548084259033,
      "learning_rate": 4.6272134203168686e-05,
      "loss": 2.3863,
      "step": 320
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.2624474763870239,
      "learning_rate": 4.615563839701771e-05,
      "loss": 2.383,
      "step": 330
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.24689935147762299,
      "learning_rate": 4.603914259086673e-05,
      "loss": 2.3737,
      "step": 340
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.2713943123817444,
      "learning_rate": 4.592264678471575e-05,
      "loss": 2.3964,
      "step": 350
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.2625623047351837,
      "learning_rate": 4.580615097856477e-05,
      "loss": 2.3795,
      "step": 360
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.2543688416481018,
      "learning_rate": 4.5689655172413794e-05,
      "loss": 2.3564,
      "step": 370
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.27071473002433777,
      "learning_rate": 4.557315936626282e-05,
      "loss": 2.3885,
      "step": 380
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.2671631872653961,
      "learning_rate": 4.545666356011184e-05,
      "loss": 2.3519,
      "step": 390
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.26280683279037476,
      "learning_rate": 4.534016775396086e-05,
      "loss": 2.3811,
      "step": 400
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.28296950459480286,
      "learning_rate": 4.5223671947809884e-05,
      "loss": 2.3559,
      "step": 410
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2689989507198334,
      "learning_rate": 4.51071761416589e-05,
      "loss": 2.3684,
      "step": 420
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3007534146308899,
      "learning_rate": 4.499068033550792e-05,
      "loss": 2.374,
      "step": 430
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2936697006225586,
      "learning_rate": 4.487418452935694e-05,
      "loss": 2.3718,
      "step": 440
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.28307080268859863,
      "learning_rate": 4.475768872320597e-05,
      "loss": 2.3807,
      "step": 450
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.28012436628341675,
      "learning_rate": 4.4641192917054986e-05,
      "loss": 2.3882,
      "step": 460
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2852919101715088,
      "learning_rate": 4.452469711090401e-05,
      "loss": 2.3958,
      "step": 470
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3014709949493408,
      "learning_rate": 4.440820130475303e-05,
      "loss": 2.3533,
      "step": 480
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.29962337017059326,
      "learning_rate": 4.429170549860206e-05,
      "loss": 2.3481,
      "step": 490
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.28248414397239685,
      "learning_rate": 4.4175209692451076e-05,
      "loss": 2.3455,
      "step": 500
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.30566680431365967,
      "learning_rate": 4.4058713886300095e-05,
      "loss": 2.3558,
      "step": 510
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.33312955498695374,
      "learning_rate": 4.3942218080149114e-05,
      "loss": 2.3654,
      "step": 520
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2854112982749939,
      "learning_rate": 4.382572227399814e-05,
      "loss": 2.3567,
      "step": 530
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3121819794178009,
      "learning_rate": 4.370922646784716e-05,
      "loss": 2.3496,
      "step": 540
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.2917586863040924,
      "learning_rate": 4.359273066169618e-05,
      "loss": 2.3291,
      "step": 550
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3005414605140686,
      "learning_rate": 4.3476234855545203e-05,
      "loss": 2.3466,
      "step": 560
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.29247596859931946,
      "learning_rate": 4.335973904939422e-05,
      "loss": 2.3257,
      "step": 570
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.31110623478889465,
      "learning_rate": 4.324324324324325e-05,
      "loss": 2.3358,
      "step": 580
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3130875527858734,
      "learning_rate": 4.312674743709227e-05,
      "loss": 2.3388,
      "step": 590
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.30929967761039734,
      "learning_rate": 4.3010251630941286e-05,
      "loss": 2.3538,
      "step": 600
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2984565794467926,
      "learning_rate": 4.289375582479031e-05,
      "loss": 2.3564,
      "step": 610
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3021906614303589,
      "learning_rate": 4.277726001863933e-05,
      "loss": 2.344,
      "step": 620
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.2904966175556183,
      "learning_rate": 4.266076421248835e-05,
      "loss": 2.3446,
      "step": 630
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.32561245560646057,
      "learning_rate": 4.2544268406337376e-05,
      "loss": 2.3329,
      "step": 640
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.30620068311691284,
      "learning_rate": 4.2427772600186395e-05,
      "loss": 2.3436,
      "step": 650
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.34552788734436035,
      "learning_rate": 4.2311276794035414e-05,
      "loss": 2.3547,
      "step": 660
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3026612401008606,
      "learning_rate": 4.219478098788443e-05,
      "loss": 2.3481,
      "step": 670
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.28864967823028564,
      "learning_rate": 4.2078285181733466e-05,
      "loss": 2.3101,
      "step": 680
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.29984793066978455,
      "learning_rate": 4.1961789375582485e-05,
      "loss": 2.3107,
      "step": 690
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3140210509300232,
      "learning_rate": 4.1845293569431504e-05,
      "loss": 2.301,
      "step": 700
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.32485559582710266,
      "learning_rate": 4.172879776328052e-05,
      "loss": 2.3269,
      "step": 710
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3034361004829407,
      "learning_rate": 4.161230195712955e-05,
      "loss": 2.3195,
      "step": 720
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.402290016412735,
      "learning_rate": 4.149580615097857e-05,
      "loss": 2.3404,
      "step": 730
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3316962718963623,
      "learning_rate": 4.1379310344827587e-05,
      "loss": 2.3047,
      "step": 740
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.34380385279655457,
      "learning_rate": 4.1262814538676606e-05,
      "loss": 2.3196,
      "step": 750
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.33674880862236023,
      "learning_rate": 4.114631873252563e-05,
      "loss": 2.3255,
      "step": 760
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.35999640822410583,
      "learning_rate": 4.102982292637465e-05,
      "loss": 2.3017,
      "step": 770
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.32786715030670166,
      "learning_rate": 4.091332712022367e-05,
      "loss": 2.2909,
      "step": 780
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3441298305988312,
      "learning_rate": 4.0796831314072695e-05,
      "loss": 2.32,
      "step": 790
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3167782127857208,
      "learning_rate": 4.068033550792172e-05,
      "loss": 2.3041,
      "step": 800
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3575933873653412,
      "learning_rate": 4.056383970177074e-05,
      "loss": 2.2981,
      "step": 810
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.34897807240486145,
      "learning_rate": 4.044734389561976e-05,
      "loss": 2.3392,
      "step": 820
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3409505784511566,
      "learning_rate": 4.033084808946878e-05,
      "loss": 2.3199,
      "step": 830
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.36676907539367676,
      "learning_rate": 4.0214352283317804e-05,
      "loss": 2.3195,
      "step": 840
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3360600173473358,
      "learning_rate": 4.009785647716682e-05,
      "loss": 2.3192,
      "step": 850
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3770172894001007,
      "learning_rate": 3.998136067101584e-05,
      "loss": 2.3286,
      "step": 860
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.34990590810775757,
      "learning_rate": 3.986486486486487e-05,
      "loss": 2.3071,
      "step": 870
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3660590648651123,
      "learning_rate": 3.974836905871389e-05,
      "loss": 2.3194,
      "step": 880
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3252420127391815,
      "learning_rate": 3.963187325256291e-05,
      "loss": 2.3238,
      "step": 890
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3790834844112396,
      "learning_rate": 3.951537744641193e-05,
      "loss": 2.349,
      "step": 900
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3362738788127899,
      "learning_rate": 3.939888164026095e-05,
      "loss": 2.3012,
      "step": 910
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.34728923439979553,
      "learning_rate": 3.9282385834109976e-05,
      "loss": 2.3145,
      "step": 920
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3651900589466095,
      "learning_rate": 3.9165890027958995e-05,
      "loss": 2.3182,
      "step": 930
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3527626693248749,
      "learning_rate": 3.9049394221808015e-05,
      "loss": 2.3189,
      "step": 940
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.361392080783844,
      "learning_rate": 3.893289841565704e-05,
      "loss": 2.3218,
      "step": 950
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.34239205718040466,
      "learning_rate": 3.881640260950606e-05,
      "loss": 2.2736,
      "step": 960
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3600570261478424,
      "learning_rate": 3.869990680335508e-05,
      "loss": 2.3111,
      "step": 970
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.39114660024642944,
      "learning_rate": 3.85834109972041e-05,
      "loss": 2.2903,
      "step": 980
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.36990079283714294,
      "learning_rate": 3.846691519105313e-05,
      "loss": 2.2998,
      "step": 990
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3464215397834778,
      "learning_rate": 3.835041938490215e-05,
      "loss": 2.2964,
      "step": 1000
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.34046417474746704,
      "learning_rate": 3.823392357875117e-05,
      "loss": 2.2883,
      "step": 1010
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3538191318511963,
      "learning_rate": 3.811742777260019e-05,
      "loss": 2.3073,
      "step": 1020
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.35219281911849976,
      "learning_rate": 3.800093196644921e-05,
      "loss": 2.2976,
      "step": 1030
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.43711143732070923,
      "learning_rate": 3.788443616029823e-05,
      "loss": 2.3011,
      "step": 1040
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.36759549379348755,
      "learning_rate": 3.776794035414725e-05,
      "loss": 2.3091,
      "step": 1050
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.3828180730342865,
      "learning_rate": 3.765144454799627e-05,
      "loss": 2.3057,
      "step": 1060
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.3678531050682068,
      "learning_rate": 3.7534948741845296e-05,
      "loss": 2.2949,
      "step": 1070
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.3522586524486542,
      "learning_rate": 3.7418452935694315e-05,
      "loss": 2.2901,
      "step": 1080
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.3911547362804413,
      "learning_rate": 3.7301957129543334e-05,
      "loss": 2.2775,
      "step": 1090
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.40725257992744446,
      "learning_rate": 3.718546132339236e-05,
      "loss": 2.2959,
      "step": 1100
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.36431968212127686,
      "learning_rate": 3.7068965517241385e-05,
      "loss": 2.3002,
      "step": 1110
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4218297600746155,
      "learning_rate": 3.6952469711090404e-05,
      "loss": 2.3038,
      "step": 1120
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.42266878485679626,
      "learning_rate": 3.6835973904939423e-05,
      "loss": 2.2903,
      "step": 1130
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3595840334892273,
      "learning_rate": 3.671947809878844e-05,
      "loss": 2.2684,
      "step": 1140
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3769528567790985,
      "learning_rate": 3.660298229263747e-05,
      "loss": 2.317,
      "step": 1150
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3823741674423218,
      "learning_rate": 3.648648648648649e-05,
      "loss": 2.2546,
      "step": 1160
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3781881332397461,
      "learning_rate": 3.6369990680335506e-05,
      "loss": 2.297,
      "step": 1170
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3925447463989258,
      "learning_rate": 3.625349487418453e-05,
      "loss": 2.2681,
      "step": 1180
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.3660098612308502,
      "learning_rate": 3.613699906803355e-05,
      "loss": 2.2881,
      "step": 1190
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.44153496623039246,
      "learning_rate": 3.602050326188258e-05,
      "loss": 2.3234,
      "step": 1200
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.39105820655822754,
      "learning_rate": 3.5904007455731596e-05,
      "loss": 2.3043,
      "step": 1210
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4015844464302063,
      "learning_rate": 3.5787511649580615e-05,
      "loss": 2.3006,
      "step": 1220
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.40291863679885864,
      "learning_rate": 3.567101584342964e-05,
      "loss": 2.2922,
      "step": 1230
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3839839696884155,
      "learning_rate": 3.555452003727866e-05,
      "loss": 2.265,
      "step": 1240
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4135332405567169,
      "learning_rate": 3.543802423112768e-05,
      "loss": 2.2867,
      "step": 1250
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.38291817903518677,
      "learning_rate": 3.5321528424976705e-05,
      "loss": 2.2938,
      "step": 1260
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4327210783958435,
      "learning_rate": 3.5205032618825724e-05,
      "loss": 2.2956,
      "step": 1270
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.41759344935417175,
      "learning_rate": 3.508853681267474e-05,
      "loss": 2.2922,
      "step": 1280
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.410495787858963,
      "learning_rate": 3.497204100652376e-05,
      "loss": 2.2956,
      "step": 1290
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3863966166973114,
      "learning_rate": 3.485554520037279e-05,
      "loss": 2.2668,
      "step": 1300
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4178207218647003,
      "learning_rate": 3.473904939422181e-05,
      "loss": 2.2757,
      "step": 1310
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4395524561405182,
      "learning_rate": 3.462255358807083e-05,
      "loss": 2.2773,
      "step": 1320
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4039997458457947,
      "learning_rate": 3.450605778191985e-05,
      "loss": 2.2787,
      "step": 1330
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.47261396050453186,
      "learning_rate": 3.438956197576888e-05,
      "loss": 2.2855,
      "step": 1340
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.40660417079925537,
      "learning_rate": 3.4273066169617896e-05,
      "loss": 2.28,
      "step": 1350
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.396541953086853,
      "learning_rate": 3.4156570363466915e-05,
      "loss": 2.272,
      "step": 1360
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.39938151836395264,
      "learning_rate": 3.4040074557315934e-05,
      "loss": 2.2754,
      "step": 1370
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4228174388408661,
      "learning_rate": 3.392357875116496e-05,
      "loss": 2.2829,
      "step": 1380
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4191414713859558,
      "learning_rate": 3.380708294501398e-05,
      "loss": 2.2689,
      "step": 1390
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4285145401954651,
      "learning_rate": 3.3690587138863e-05,
      "loss": 2.2791,
      "step": 1400
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4220919609069824,
      "learning_rate": 3.3574091332712024e-05,
      "loss": 2.2721,
      "step": 1410
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4260554909706116,
      "learning_rate": 3.345759552656105e-05,
      "loss": 2.2439,
      "step": 1420
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4330185353755951,
      "learning_rate": 3.334109972041007e-05,
      "loss": 2.2534,
      "step": 1430
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.41636061668395996,
      "learning_rate": 3.322460391425909e-05,
      "loss": 2.2571,
      "step": 1440
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.41740161180496216,
      "learning_rate": 3.310810810810811e-05,
      "loss": 2.2543,
      "step": 1450
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4150683283805847,
      "learning_rate": 3.299161230195713e-05,
      "loss": 2.2439,
      "step": 1460
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4392189383506775,
      "learning_rate": 3.287511649580615e-05,
      "loss": 2.2605,
      "step": 1470
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4263838231563568,
      "learning_rate": 3.275862068965517e-05,
      "loss": 2.2469,
      "step": 1480
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.471886545419693,
      "learning_rate": 3.2642124883504197e-05,
      "loss": 2.2592,
      "step": 1490
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.45181554555892944,
      "learning_rate": 3.2525629077353216e-05,
      "loss": 2.268,
      "step": 1500
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.40875473618507385,
      "learning_rate": 3.2409133271202235e-05,
      "loss": 2.2585,
      "step": 1510
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.46743613481521606,
      "learning_rate": 3.229263746505126e-05,
      "loss": 2.2575,
      "step": 1520
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.41415324807167053,
      "learning_rate": 3.2176141658900286e-05,
      "loss": 2.2635,
      "step": 1530
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.4574092626571655,
      "learning_rate": 3.2059645852749305e-05,
      "loss": 2.2529,
      "step": 1540
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.44880974292755127,
      "learning_rate": 3.1943150046598324e-05,
      "loss": 2.2345,
      "step": 1550
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.44262003898620605,
      "learning_rate": 3.182665424044734e-05,
      "loss": 2.2629,
      "step": 1560
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4569621682167053,
      "learning_rate": 3.171015843429637e-05,
      "loss": 2.2699,
      "step": 1570
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4764057695865631,
      "learning_rate": 3.159366262814539e-05,
      "loss": 2.2489,
      "step": 1580
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.489030659198761,
      "learning_rate": 3.147716682199441e-05,
      "loss": 2.2459,
      "step": 1590
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4103184938430786,
      "learning_rate": 3.1360671015843426e-05,
      "loss": 2.258,
      "step": 1600
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4796679615974426,
      "learning_rate": 3.124417520969245e-05,
      "loss": 2.2713,
      "step": 1610
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4798326790332794,
      "learning_rate": 3.112767940354148e-05,
      "loss": 2.2565,
      "step": 1620
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.41441237926483154,
      "learning_rate": 3.10111835973905e-05,
      "loss": 2.2078,
      "step": 1630
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.45114436745643616,
      "learning_rate": 3.0894687791239516e-05,
      "loss": 2.266,
      "step": 1640
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.47561174631118774,
      "learning_rate": 3.077819198508854e-05,
      "loss": 2.2456,
      "step": 1650
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.45768705010414124,
      "learning_rate": 3.066169617893756e-05,
      "loss": 2.2387,
      "step": 1660
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4187476634979248,
      "learning_rate": 3.054520037278658e-05,
      "loss": 2.2374,
      "step": 1670
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.48294344544410706,
      "learning_rate": 3.0428704566635602e-05,
      "loss": 2.2457,
      "step": 1680
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5334978103637695,
      "learning_rate": 3.031220876048462e-05,
      "loss": 2.2334,
      "step": 1690
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4210706651210785,
      "learning_rate": 3.0195712954333644e-05,
      "loss": 2.2518,
      "step": 1700
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.47434648871421814,
      "learning_rate": 3.0079217148182666e-05,
      "loss": 2.2449,
      "step": 1710
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.45915713906288147,
      "learning_rate": 2.9962721342031692e-05,
      "loss": 2.2735,
      "step": 1720
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4550193250179291,
      "learning_rate": 2.984622553588071e-05,
      "loss": 2.2219,
      "step": 1730
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5029726028442383,
      "learning_rate": 2.9729729729729733e-05,
      "loss": 2.2437,
      "step": 1740
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4644174575805664,
      "learning_rate": 2.9613233923578752e-05,
      "loss": 2.2637,
      "step": 1750
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5066208839416504,
      "learning_rate": 2.9496738117427775e-05,
      "loss": 2.2264,
      "step": 1760
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4676838219165802,
      "learning_rate": 2.9380242311276797e-05,
      "loss": 2.2327,
      "step": 1770
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5224447846412659,
      "learning_rate": 2.9263746505125816e-05,
      "loss": 2.2729,
      "step": 1780
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.44789668917655945,
      "learning_rate": 2.914725069897484e-05,
      "loss": 2.2193,
      "step": 1790
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4971928298473358,
      "learning_rate": 2.9030754892823857e-05,
      "loss": 2.2219,
      "step": 1800
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4910319745540619,
      "learning_rate": 2.891425908667288e-05,
      "loss": 2.2651,
      "step": 1810
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.47094035148620605,
      "learning_rate": 2.87977632805219e-05,
      "loss": 2.2492,
      "step": 1820
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.441578209400177,
      "learning_rate": 2.8681267474370925e-05,
      "loss": 2.2083,
      "step": 1830
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4596360921859741,
      "learning_rate": 2.8564771668219947e-05,
      "loss": 2.2165,
      "step": 1840
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5173614621162415,
      "learning_rate": 2.844827586206897e-05,
      "loss": 2.2188,
      "step": 1850
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5400665998458862,
      "learning_rate": 2.833178005591799e-05,
      "loss": 2.2279,
      "step": 1860
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.48835623264312744,
      "learning_rate": 2.821528424976701e-05,
      "loss": 2.2093,
      "step": 1870
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5075654983520508,
      "learning_rate": 2.809878844361603e-05,
      "loss": 2.2049,
      "step": 1880
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.523875892162323,
      "learning_rate": 2.7982292637465052e-05,
      "loss": 2.2147,
      "step": 1890
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5420220494270325,
      "learning_rate": 2.786579683131407e-05,
      "loss": 2.2277,
      "step": 1900
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5385499000549316,
      "learning_rate": 2.7749301025163094e-05,
      "loss": 2.22,
      "step": 1910
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5419403910636902,
      "learning_rate": 2.7632805219012113e-05,
      "loss": 2.2289,
      "step": 1920
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.530276894569397,
      "learning_rate": 2.7516309412861142e-05,
      "loss": 2.226,
      "step": 1930
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5047475695610046,
      "learning_rate": 2.739981360671016e-05,
      "loss": 2.2069,
      "step": 1940
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5210863947868347,
      "learning_rate": 2.7283317800559184e-05,
      "loss": 2.2358,
      "step": 1950
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5238314867019653,
      "learning_rate": 2.7166821994408203e-05,
      "loss": 2.2327,
      "step": 1960
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.48575088381767273,
      "learning_rate": 2.7050326188257225e-05,
      "loss": 2.1973,
      "step": 1970
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5139735341072083,
      "learning_rate": 2.6933830382106244e-05,
      "loss": 2.1946,
      "step": 1980
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5578981041908264,
      "learning_rate": 2.6817334575955266e-05,
      "loss": 2.205,
      "step": 1990
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5300214886665344,
      "learning_rate": 2.670083876980429e-05,
      "loss": 2.2179,
      "step": 2000
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5362910628318787,
      "learning_rate": 2.6584342963653308e-05,
      "loss": 2.2051,
      "step": 2010
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4992552697658539,
      "learning_rate": 2.646784715750233e-05,
      "loss": 2.2119,
      "step": 2020
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5440447926521301,
      "learning_rate": 2.635135135135135e-05,
      "loss": 2.2249,
      "step": 2030
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.49933090806007385,
      "learning_rate": 2.6234855545200375e-05,
      "loss": 2.2183,
      "step": 2040
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5772737264633179,
      "learning_rate": 2.6118359739049398e-05,
      "loss": 2.2235,
      "step": 2050
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.46486496925354004,
      "learning_rate": 2.6001863932898417e-05,
      "loss": 2.2312,
      "step": 2060
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5185267329216003,
      "learning_rate": 2.588536812674744e-05,
      "loss": 2.1996,
      "step": 2070
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5128301382064819,
      "learning_rate": 2.576887232059646e-05,
      "loss": 2.2175,
      "step": 2080
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5155572891235352,
      "learning_rate": 2.565237651444548e-05,
      "loss": 2.2091,
      "step": 2090
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5175172090530396,
      "learning_rate": 2.5535880708294503e-05,
      "loss": 2.2022,
      "step": 2100
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5575586557388306,
      "learning_rate": 2.5419384902143522e-05,
      "loss": 2.201,
      "step": 2110
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5431041121482849,
      "learning_rate": 2.5302889095992544e-05,
      "loss": 2.211,
      "step": 2120
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5650783777236938,
      "learning_rate": 2.5186393289841563e-05,
      "loss": 2.2175,
      "step": 2130
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5403300523757935,
      "learning_rate": 2.5069897483690592e-05,
      "loss": 2.2406,
      "step": 2140
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5103176236152649,
      "learning_rate": 2.4953401677539608e-05,
      "loss": 2.1968,
      "step": 2150
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.472035676240921,
      "learning_rate": 2.483690587138863e-05,
      "loss": 2.2023,
      "step": 2160
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5019587874412537,
      "learning_rate": 2.4720410065237653e-05,
      "loss": 2.2028,
      "step": 2170
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5421128273010254,
      "learning_rate": 2.4603914259086675e-05,
      "loss": 2.2181,
      "step": 2180
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5976943373680115,
      "learning_rate": 2.4487418452935694e-05,
      "loss": 2.1967,
      "step": 2190
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5090937614440918,
      "learning_rate": 2.4370922646784717e-05,
      "loss": 2.2039,
      "step": 2200
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5607552528381348,
      "learning_rate": 2.4254426840633736e-05,
      "loss": 2.1904,
      "step": 2210
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5722289085388184,
      "learning_rate": 2.413793103448276e-05,
      "loss": 2.205,
      "step": 2220
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5018388628959656,
      "learning_rate": 2.402143522833178e-05,
      "loss": 2.1899,
      "step": 2230
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5034250617027283,
      "learning_rate": 2.3904939422180803e-05,
      "loss": 2.2226,
      "step": 2240
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5190451145172119,
      "learning_rate": 2.3788443616029822e-05,
      "loss": 2.1887,
      "step": 2250
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6071779727935791,
      "learning_rate": 2.3671947809878845e-05,
      "loss": 2.1901,
      "step": 2260
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5345807671546936,
      "learning_rate": 2.3555452003727867e-05,
      "loss": 2.2086,
      "step": 2270
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6120887994766235,
      "learning_rate": 2.343895619757689e-05,
      "loss": 2.1848,
      "step": 2280
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5170578956604004,
      "learning_rate": 2.332246039142591e-05,
      "loss": 2.2069,
      "step": 2290
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5151667594909668,
      "learning_rate": 2.320596458527493e-05,
      "loss": 2.1983,
      "step": 2300
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6538474559783936,
      "learning_rate": 2.3089468779123953e-05,
      "loss": 2.2109,
      "step": 2310
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.52880859375,
      "learning_rate": 2.2972972972972976e-05,
      "loss": 2.1946,
      "step": 2320
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5677123069763184,
      "learning_rate": 2.2856477166821995e-05,
      "loss": 2.1712,
      "step": 2330
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5352494716644287,
      "learning_rate": 2.2739981360671017e-05,
      "loss": 2.1865,
      "step": 2340
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4914665222167969,
      "learning_rate": 2.262348555452004e-05,
      "loss": 2.2157,
      "step": 2350
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.49284520745277405,
      "learning_rate": 2.250698974836906e-05,
      "loss": 2.194,
      "step": 2360
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5116947889328003,
      "learning_rate": 2.239049394221808e-05,
      "loss": 2.1924,
      "step": 2370
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5304252505302429,
      "learning_rate": 2.2273998136067103e-05,
      "loss": 2.2248,
      "step": 2380
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.53001469373703,
      "learning_rate": 2.2157502329916126e-05,
      "loss": 2.1853,
      "step": 2390
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5339929461479187,
      "learning_rate": 2.2041006523765145e-05,
      "loss": 2.1951,
      "step": 2400
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5187262296676636,
      "learning_rate": 2.1924510717614167e-05,
      "loss": 2.1833,
      "step": 2410
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5983812212944031,
      "learning_rate": 2.1808014911463186e-05,
      "loss": 2.2183,
      "step": 2420
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6269989609718323,
      "learning_rate": 2.1691519105312212e-05,
      "loss": 2.1837,
      "step": 2430
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5510775446891785,
      "learning_rate": 2.157502329916123e-05,
      "loss": 2.2077,
      "step": 2440
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5204881429672241,
      "learning_rate": 2.1458527493010253e-05,
      "loss": 2.1942,
      "step": 2450
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5425204634666443,
      "learning_rate": 2.1342031686859272e-05,
      "loss": 2.2046,
      "step": 2460
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5599619150161743,
      "learning_rate": 2.1225535880708295e-05,
      "loss": 2.1862,
      "step": 2470
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5963820815086365,
      "learning_rate": 2.1109040074557317e-05,
      "loss": 2.1919,
      "step": 2480
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5514874458312988,
      "learning_rate": 2.099254426840634e-05,
      "loss": 2.1718,
      "step": 2490
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5256288647651672,
      "learning_rate": 2.087604846225536e-05,
      "loss": 2.164,
      "step": 2500
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.555439829826355,
      "learning_rate": 2.075955265610438e-05,
      "loss": 2.1854,
      "step": 2510
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6360782384872437,
      "learning_rate": 2.06430568499534e-05,
      "loss": 2.1987,
      "step": 2520
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.588573694229126,
      "learning_rate": 2.0526561043802426e-05,
      "loss": 2.1657,
      "step": 2530
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5790947079658508,
      "learning_rate": 2.0410065237651445e-05,
      "loss": 2.2224,
      "step": 2540
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5971891283988953,
      "learning_rate": 2.0293569431500467e-05,
      "loss": 2.2006,
      "step": 2550
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.547694742679596,
      "learning_rate": 2.0177073625349486e-05,
      "loss": 2.2056,
      "step": 2560
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.552721381187439,
      "learning_rate": 2.006057781919851e-05,
      "loss": 2.1806,
      "step": 2570
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.556118905544281,
      "learning_rate": 1.994408201304753e-05,
      "loss": 2.1852,
      "step": 2580
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.573971152305603,
      "learning_rate": 1.9827586206896554e-05,
      "loss": 2.1906,
      "step": 2590
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6441878080368042,
      "learning_rate": 1.9711090400745573e-05,
      "loss": 2.1999,
      "step": 2600
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5976534485816956,
      "learning_rate": 1.9594594594594595e-05,
      "loss": 2.2144,
      "step": 2610
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5279497504234314,
      "learning_rate": 1.9478098788443618e-05,
      "loss": 2.1866,
      "step": 2620
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5568758845329285,
      "learning_rate": 1.9361602982292637e-05,
      "loss": 2.1873,
      "step": 2630
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6236107349395752,
      "learning_rate": 1.924510717614166e-05,
      "loss": 2.1769,
      "step": 2640
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5622202754020691,
      "learning_rate": 1.912861136999068e-05,
      "loss": 2.1977,
      "step": 2650
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5785645246505737,
      "learning_rate": 1.9012115563839704e-05,
      "loss": 2.172,
      "step": 2660
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5686667561531067,
      "learning_rate": 1.8895619757688723e-05,
      "loss": 2.1767,
      "step": 2670
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5602458119392395,
      "learning_rate": 1.8779123951537745e-05,
      "loss": 2.2192,
      "step": 2680
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5781643390655518,
      "learning_rate": 1.8662628145386768e-05,
      "loss": 2.1977,
      "step": 2690
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5934684872627258,
      "learning_rate": 1.854613233923579e-05,
      "loss": 2.1853,
      "step": 2700
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5312116742134094,
      "learning_rate": 1.842963653308481e-05,
      "loss": 2.1896,
      "step": 2710
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5069032907485962,
      "learning_rate": 1.831314072693383e-05,
      "loss": 2.193,
      "step": 2720
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6292213201522827,
      "learning_rate": 1.819664492078285e-05,
      "loss": 2.2129,
      "step": 2730
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5541000962257385,
      "learning_rate": 1.8080149114631876e-05,
      "loss": 2.1882,
      "step": 2740
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.529640257358551,
      "learning_rate": 1.7963653308480895e-05,
      "loss": 2.2003,
      "step": 2750
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6196367740631104,
      "learning_rate": 1.7847157502329918e-05,
      "loss": 2.1773,
      "step": 2760
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5211873650550842,
      "learning_rate": 1.7730661696178937e-05,
      "loss": 2.1933,
      "step": 2770
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5705205202102661,
      "learning_rate": 1.761416589002796e-05,
      "loss": 2.1825,
      "step": 2780
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5902969241142273,
      "learning_rate": 1.749767008387698e-05,
      "loss": 2.1669,
      "step": 2790
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.588894248008728,
      "learning_rate": 1.7381174277726004e-05,
      "loss": 2.1818,
      "step": 2800
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5403002500534058,
      "learning_rate": 1.7264678471575023e-05,
      "loss": 2.2046,
      "step": 2810
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5621733069419861,
      "learning_rate": 1.7148182665424046e-05,
      "loss": 2.1724,
      "step": 2820
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5976819396018982,
      "learning_rate": 1.7031686859273065e-05,
      "loss": 2.1658,
      "step": 2830
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.645318865776062,
      "learning_rate": 1.691519105312209e-05,
      "loss": 2.1915,
      "step": 2840
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5780615210533142,
      "learning_rate": 1.679869524697111e-05,
      "loss": 2.1683,
      "step": 2850
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.562960684299469,
      "learning_rate": 1.6682199440820132e-05,
      "loss": 2.1865,
      "step": 2860
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.581778347492218,
      "learning_rate": 1.656570363466915e-05,
      "loss": 2.1999,
      "step": 2870
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6011843085289001,
      "learning_rate": 1.6449207828518173e-05,
      "loss": 2.1822,
      "step": 2880
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5691461563110352,
      "learning_rate": 1.6332712022367196e-05,
      "loss": 2.1961,
      "step": 2890
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5484930872917175,
      "learning_rate": 1.6216216216216218e-05,
      "loss": 2.2001,
      "step": 2900
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5893412232398987,
      "learning_rate": 1.6099720410065237e-05,
      "loss": 2.1759,
      "step": 2910
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5750992894172668,
      "learning_rate": 1.598322460391426e-05,
      "loss": 2.1807,
      "step": 2920
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6150139570236206,
      "learning_rate": 1.5866728797763282e-05,
      "loss": 2.1739,
      "step": 2930
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5689942836761475,
      "learning_rate": 1.57502329916123e-05,
      "loss": 2.1631,
      "step": 2940
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5826297402381897,
      "learning_rate": 1.5633737185461327e-05,
      "loss": 2.1838,
      "step": 2950
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5972347259521484,
      "learning_rate": 1.5517241379310346e-05,
      "loss": 2.2095,
      "step": 2960
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.6014872193336487,
      "learning_rate": 1.5400745573159368e-05,
      "loss": 2.1841,
      "step": 2970
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5847914218902588,
      "learning_rate": 1.5284249767008387e-05,
      "loss": 2.1642,
      "step": 2980
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5851702690124512,
      "learning_rate": 1.5167753960857408e-05,
      "loss": 2.1867,
      "step": 2990
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6517285108566284,
      "learning_rate": 1.5051258154706432e-05,
      "loss": 2.2163,
      "step": 3000
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5961496829986572,
      "learning_rate": 1.4934762348555453e-05,
      "loss": 2.2005,
      "step": 3010
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5871349573135376,
      "learning_rate": 1.4818266542404474e-05,
      "loss": 2.1896,
      "step": 3020
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5762670636177063,
      "learning_rate": 1.4701770736253496e-05,
      "loss": 2.193,
      "step": 3030
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.568118691444397,
      "learning_rate": 1.4585274930102517e-05,
      "loss": 2.1837,
      "step": 3040
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.575383722782135,
      "learning_rate": 1.4468779123951539e-05,
      "loss": 2.1379,
      "step": 3050
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5874687433242798,
      "learning_rate": 1.435228331780056e-05,
      "loss": 2.1674,
      "step": 3060
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5402302742004395,
      "learning_rate": 1.4235787511649582e-05,
      "loss": 2.1496,
      "step": 3070
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5343434810638428,
      "learning_rate": 1.4119291705498603e-05,
      "loss": 2.1851,
      "step": 3080
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6751231551170349,
      "learning_rate": 1.4002795899347624e-05,
      "loss": 2.1939,
      "step": 3090
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5886486172676086,
      "learning_rate": 1.3886300093196648e-05,
      "loss": 2.1839,
      "step": 3100
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6681378483772278,
      "learning_rate": 1.3769804287045668e-05,
      "loss": 2.1779,
      "step": 3110
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6325430274009705,
      "learning_rate": 1.365330848089469e-05,
      "loss": 2.1784,
      "step": 3120
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5899481773376465,
      "learning_rate": 1.353681267474371e-05,
      "loss": 2.1418,
      "step": 3130
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5872910022735596,
      "learning_rate": 1.342031686859273e-05,
      "loss": 2.1755,
      "step": 3140
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5936540961265564,
      "learning_rate": 1.3303821062441751e-05,
      "loss": 2.1964,
      "step": 3150
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5663030743598938,
      "learning_rate": 1.3187325256290775e-05,
      "loss": 2.1919,
      "step": 3160
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5389207005500793,
      "learning_rate": 1.3070829450139796e-05,
      "loss": 2.1745,
      "step": 3170
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6262459754943848,
      "learning_rate": 1.2954333643988817e-05,
      "loss": 2.1433,
      "step": 3180
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5613252520561218,
      "learning_rate": 1.2837837837837838e-05,
      "loss": 2.1998,
      "step": 3190
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5967008471488953,
      "learning_rate": 1.2721342031686858e-05,
      "loss": 2.1861,
      "step": 3200
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5799368619918823,
      "learning_rate": 1.2604846225535882e-05,
      "loss": 2.1605,
      "step": 3210
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6179410815238953,
      "learning_rate": 1.2488350419384903e-05,
      "loss": 2.1587,
      "step": 3220
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.625145435333252,
      "learning_rate": 1.2371854613233924e-05,
      "loss": 2.2057,
      "step": 3230
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6010167598724365,
      "learning_rate": 1.2255358807082945e-05,
      "loss": 2.1823,
      "step": 3240
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6017308235168457,
      "learning_rate": 1.2138863000931967e-05,
      "loss": 2.1802,
      "step": 3250
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5844850540161133,
      "learning_rate": 1.2022367194780988e-05,
      "loss": 2.1637,
      "step": 3260
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6172743439674377,
      "learning_rate": 1.190587138863001e-05,
      "loss": 2.1843,
      "step": 3270
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5921015739440918,
      "learning_rate": 1.1789375582479031e-05,
      "loss": 2.1874,
      "step": 3280
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5876815915107727,
      "learning_rate": 1.1672879776328052e-05,
      "loss": 2.1528,
      "step": 3290
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5696107149124146,
      "learning_rate": 1.1556383970177074e-05,
      "loss": 2.1679,
      "step": 3300
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5889853239059448,
      "learning_rate": 1.1439888164026095e-05,
      "loss": 2.184,
      "step": 3310
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5264036655426025,
      "learning_rate": 1.1323392357875117e-05,
      "loss": 2.1713,
      "step": 3320
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5952780246734619,
      "learning_rate": 1.1206896551724138e-05,
      "loss": 2.1788,
      "step": 3330
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5612215995788574,
      "learning_rate": 1.109040074557316e-05,
      "loss": 2.167,
      "step": 3340
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5813755989074707,
      "learning_rate": 1.0973904939422181e-05,
      "loss": 2.1836,
      "step": 3350
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6146261692047119,
      "learning_rate": 1.0857409133271203e-05,
      "loss": 2.1883,
      "step": 3360
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5787060260772705,
      "learning_rate": 1.0740913327120224e-05,
      "loss": 2.1728,
      "step": 3370
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.582768976688385,
      "learning_rate": 1.0624417520969247e-05,
      "loss": 2.2036,
      "step": 3380
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5697429776191711,
      "learning_rate": 1.0507921714818267e-05,
      "loss": 2.1743,
      "step": 3390
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.584430456161499,
      "learning_rate": 1.039142590866729e-05,
      "loss": 2.1593,
      "step": 3400
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6209235787391663,
      "learning_rate": 1.027493010251631e-05,
      "loss": 2.1604,
      "step": 3410
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5931470990180969,
      "learning_rate": 1.0158434296365331e-05,
      "loss": 2.1708,
      "step": 3420
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5896593928337097,
      "learning_rate": 1.0041938490214354e-05,
      "loss": 2.1877,
      "step": 3430
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5776058435440063,
      "learning_rate": 9.925442684063374e-06,
      "loss": 2.156,
      "step": 3440
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.622071385383606,
      "learning_rate": 9.808946877912395e-06,
      "loss": 2.1707,
      "step": 3450
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6270806193351746,
      "learning_rate": 9.692451071761417e-06,
      "loss": 2.1849,
      "step": 3460
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.651921272277832,
      "learning_rate": 9.575955265610438e-06,
      "loss": 2.1798,
      "step": 3470
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.5838229060173035,
      "learning_rate": 9.45945945945946e-06,
      "loss": 2.1874,
      "step": 3480
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6083759665489197,
      "learning_rate": 9.342963653308481e-06,
      "loss": 2.1943,
      "step": 3490
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6521278619766235,
      "learning_rate": 9.226467847157502e-06,
      "loss": 2.1912,
      "step": 3500
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5868666768074036,
      "learning_rate": 9.109972041006524e-06,
      "loss": 2.1752,
      "step": 3510
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6655377149581909,
      "learning_rate": 8.993476234855545e-06,
      "loss": 2.1908,
      "step": 3520
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6363030672073364,
      "learning_rate": 8.876980428704568e-06,
      "loss": 2.1795,
      "step": 3530
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6767922639846802,
      "learning_rate": 8.760484622553588e-06,
      "loss": 2.1925,
      "step": 3540
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6014010310173035,
      "learning_rate": 8.643988816402609e-06,
      "loss": 2.1728,
      "step": 3550
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6173271536827087,
      "learning_rate": 8.527493010251631e-06,
      "loss": 2.1667,
      "step": 3560
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5556443333625793,
      "learning_rate": 8.410997204100652e-06,
      "loss": 2.142,
      "step": 3570
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6152588129043579,
      "learning_rate": 8.294501397949673e-06,
      "loss": 2.1458,
      "step": 3580
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6302415728569031,
      "learning_rate": 8.178005591798695e-06,
      "loss": 2.1538,
      "step": 3590
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6721239686012268,
      "learning_rate": 8.061509785647716e-06,
      "loss": 2.1723,
      "step": 3600
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6400014758110046,
      "learning_rate": 7.945013979496738e-06,
      "loss": 2.1643,
      "step": 3610
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5960135459899902,
      "learning_rate": 7.828518173345759e-06,
      "loss": 2.168,
      "step": 3620
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5430383086204529,
      "learning_rate": 7.712022367194782e-06,
      "loss": 2.1633,
      "step": 3630
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.709771990776062,
      "learning_rate": 7.595526561043803e-06,
      "loss": 2.1969,
      "step": 3640
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6244368553161621,
      "learning_rate": 7.479030754892824e-06,
      "loss": 2.1817,
      "step": 3650
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.607563853263855,
      "learning_rate": 7.362534948741846e-06,
      "loss": 2.1626,
      "step": 3660
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6009837985038757,
      "learning_rate": 7.246039142590867e-06,
      "loss": 2.1742,
      "step": 3670
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6461438536643982,
      "learning_rate": 7.129543336439888e-06,
      "loss": 2.1609,
      "step": 3680
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.5898503661155701,
      "learning_rate": 7.01304753028891e-06,
      "loss": 2.1507,
      "step": 3690
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6917389035224915,
      "learning_rate": 6.896551724137932e-06,
      "loss": 2.1557,
      "step": 3700
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.5405216217041016,
      "learning_rate": 6.780055917986952e-06,
      "loss": 2.1765,
      "step": 3710
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.614811897277832,
      "learning_rate": 6.663560111835975e-06,
      "loss": 2.1925,
      "step": 3720
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.563270092010498,
      "learning_rate": 6.5470643056849955e-06,
      "loss": 2.1519,
      "step": 3730
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5930150151252747,
      "learning_rate": 6.430568499534018e-06,
      "loss": 2.1887,
      "step": 3740
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5437409281730652,
      "learning_rate": 6.314072693383039e-06,
      "loss": 2.1582,
      "step": 3750
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6412607431411743,
      "learning_rate": 6.19757688723206e-06,
      "loss": 2.1653,
      "step": 3760
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5623353123664856,
      "learning_rate": 6.081081081081082e-06,
      "loss": 2.1696,
      "step": 3770
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6981320381164551,
      "learning_rate": 5.9645852749301025e-06,
      "loss": 2.1746,
      "step": 3780
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5857828259468079,
      "learning_rate": 5.848089468779124e-06,
      "loss": 2.1651,
      "step": 3790
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5999428033828735,
      "learning_rate": 5.731593662628146e-06,
      "loss": 2.1615,
      "step": 3800
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.615135133266449,
      "learning_rate": 5.615097856477167e-06,
      "loss": 2.1717,
      "step": 3810
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5736832022666931,
      "learning_rate": 5.498602050326188e-06,
      "loss": 2.1589,
      "step": 3820
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.572818398475647,
      "learning_rate": 5.3821062441752095e-06,
      "loss": 2.1754,
      "step": 3830
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5855633616447449,
      "learning_rate": 5.265610438024231e-06,
      "loss": 2.16,
      "step": 3840
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.58467698097229,
      "learning_rate": 5.149114631873253e-06,
      "loss": 2.1376,
      "step": 3850
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6573384404182434,
      "learning_rate": 5.032618825722274e-06,
      "loss": 2.1568,
      "step": 3860
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5617899894714355,
      "learning_rate": 4.916123019571296e-06,
      "loss": 2.1466,
      "step": 3870
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.600816011428833,
      "learning_rate": 4.799627213420317e-06,
      "loss": 2.1506,
      "step": 3880
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6216878890991211,
      "learning_rate": 4.683131407269339e-06,
      "loss": 2.1358,
      "step": 3890
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6071277856826782,
      "learning_rate": 4.56663560111836e-06,
      "loss": 2.1793,
      "step": 3900
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6228756308555603,
      "learning_rate": 4.450139794967381e-06,
      "loss": 2.1949,
      "step": 3910
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6439198851585388,
      "learning_rate": 4.333643988816403e-06,
      "loss": 2.1612,
      "step": 3920
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6428323984146118,
      "learning_rate": 4.217148182665424e-06,
      "loss": 2.1657,
      "step": 3930
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6091379523277283,
      "learning_rate": 4.100652376514446e-06,
      "loss": 2.1979,
      "step": 3940
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5873124599456787,
      "learning_rate": 3.984156570363467e-06,
      "loss": 2.1601,
      "step": 3950
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5774399042129517,
      "learning_rate": 3.867660764212488e-06,
      "loss": 2.1718,
      "step": 3960
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6064476370811462,
      "learning_rate": 3.75116495806151e-06,
      "loss": 2.1616,
      "step": 3970
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.6191902160644531,
      "learning_rate": 3.6346691519105317e-06,
      "loss": 2.1863,
      "step": 3980
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.6191800236701965,
      "learning_rate": 3.5181733457595525e-06,
      "loss": 2.1629,
      "step": 3990
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5471014976501465,
      "learning_rate": 3.401677539608574e-06,
      "loss": 2.1441,
      "step": 4000
    }
  ],
  "logging_steps": 10,
  "max_steps": 4292,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1000,
  "total_flos": 1.1665554877815194e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
